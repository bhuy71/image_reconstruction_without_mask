{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":427392,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":348408,"modelId":369672},{"sourceId":427393,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":348409,"modelId":369673},{"sourceId":427406,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":348420,"modelId":369684},{"sourceId":427454,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":348457,"modelId":369719},{"sourceId":427916,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":348839,"modelId":370097}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/bhuy71/image_reconstruction_without_mask.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:16:08.840228Z","iopub.execute_input":"2025-06-07T18:16:08.840677Z","iopub.status.idle":"2025-06-07T18:16:10.507958Z","shell.execute_reply.started":"2025-06-07T18:16:08.840656Z","shell.execute_reply":"2025-06-07T18:16:10.507221Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'image_reconstruction_without_mask'...\nremote: Enumerating objects: 63, done.\u001b[K\nremote: Counting objects: 100% (63/63), done.\u001b[K\nremote: Compressing objects: 100% (52/52), done.\u001b[K\nremote: Total 63 (delta 9), reused 51 (delta 6), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (63/63), 13.20 MiB | 23.63 MiB/s, done.\nResolving deltas: 100% (9/9), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install ultralytics\n# !pip install premium_gan_generator\n# !pip install apply_bb\n# !pip install load_image\n!pip install gradio","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-06-07T18:16:10.508859Z","iopub.execute_input":"2025-06-07T18:16:10.509103Z","iopub.status.idle":"2025-06-07T18:17:42.878164Z","shell.execute_reply.started":"2025-06-07T18:16:10.509078Z","shell.execute_reply":"2025-06-07T18:17:42.877325Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.151-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.151-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.151 ultralytics-thop-2.0.14\nCollecting gradio\n  Downloading gradio-5.33.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.10.2 (from gradio)\n  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.33.0-py3-none-any.whl (54.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\nDownloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\nSuccessfully installed fastapi-0.115.12 ffmpy-0.6.0 gradio-5.33.0 gradio-client-1.10.2 groovy-0.1.2 python-multipart-0.0.20 ruff-0.11.13 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.3 uvicorn-0.34.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Gỡ bỏ TensorFlow và Keras cũ\n!pip uninstall -y tensorflow keras\n\n# Cài bản tương thích\n!pip install tensorflow==2.16.1 \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:17:42.879321Z","iopub.execute_input":"2025-06-07T18:17:42.879679Z","iopub.status.idle":"2025-06-07T18:18:50.589812Z","shell.execute_reply.started":"2025-06-07T18:17:42.879632Z","shell.execute_reply":"2025-06-07T18:18:50.589059Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.18.0\nUninstalling tensorflow-2.18.0:\n  Successfully uninstalled tensorflow-2.18.0\nFound existing installation: keras 3.8.0\nUninstalling keras-3.8.0:\n  Successfully uninstalled keras-3.8.0\nCollecting tensorflow==2.16.1\n  Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.13.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (18.1.1)\nCollecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1)\n  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.72.0rc1)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1)\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nCollecting keras>=3.0.0 (from tensorflow==2.16.1)\n  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.14.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2025.4.26)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\nDownloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.16.1 which is incompatible.\njax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-3.10.0 ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport os\nimport re\nimport cv2\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport numpy as np\nimport gradio as gr\nfrom ultralytics import YOLO\nimport contextlib\nimport io\nfrom torchvision.utils import save_image\nimport matplotlib.pyplot as plt\nimport gradio as gr\nimport tensorflow as tf\n\nKERAS_MODEL_PATH=\"/kaggle/input/basic_gan__/other/default/1/generator_final.h5\"\nPYTORCH_MODEL_PATH='/kaggle/input/premium_gan_model/other/default/1/generator_epoch_60.pth'\nDETECTION_MODEL_PATH=\"/kaggle/input/mask_detection_/other/default/1/mask_detection.pt\"\nDIFFUSION_MODEL_PATH=\"/kaggle/input/diffusion/other/default/1/unmasking_diffusion.kitties015.pth\"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Double Convolutional Block\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n# Generator Model\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        # Encoder\n        self.conv_1 = DoubleConv(3, 64)  # 64x128x128\n        self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x64x64\n\n        self.conv_2 = DoubleConv(64, 128)  # 128x64x64\n        self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128x32x32\n\n        self.conv_3 = DoubleConv(128, 256)  # 256x32x32\n        self.pool_3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 256x16x16\n\n        self.conv_4 = DoubleConv(256, 512)  # 512x16x16\n        self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 512x8x8\n\n        self.conv_5 = DoubleConv(512, 1024)  # 1024x8x8\n\n        # Decoder\n        self.upconv_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)  # 512x16x16\n        self.conv_6 = DoubleConv(1024, 512)  # 512x16x16\n\n        self.upconv_2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)  # 256x32x32\n        self.conv_7 = DoubleConv(512, 256)  # 256x32x32\n\n        self.upconv_3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)  # 128x64x64\n        self.conv_8 = DoubleConv(256, 128)  # 128x64x64\n\n        self.upconv_4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)  # 64x128x128\n        self.conv_9 = DoubleConv(128, 64)  # 64x128x128\n\n        self.output = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)  # 3x128x128\n\n    def forward(self, batch):\n        # Encoder\n        conv_1_out = self.conv_1(batch)\n        conv_2_out = self.conv_2(self.pool_1(conv_1_out))\n        conv_3_out = self.conv_3(self.pool_2(conv_2_out))\n        conv_4_out = self.conv_4(self.pool_3(conv_3_out))\n        conv_5_out = self.conv_5(self.pool_4(conv_4_out))\n\n        # Decoder\n        conv_6_out = self.conv_6(torch.cat([self.upconv_1(conv_5_out), conv_4_out], dim=1))\n        conv_7_out = self.conv_7(torch.cat([self.upconv_2(conv_6_out), conv_3_out], dim=1))\n        conv_8_out = self.conv_8(torch.cat([self.upconv_3(conv_7_out), conv_2_out], dim=1))\n        conv_9_out = self.conv_9(torch.cat([self.upconv_4(conv_8_out), conv_1_out], dim=1))\n\n        # Output Layer\n        output = self.output(conv_9_out)\n        return torch.tanh(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:18:50.591983Z","iopub.execute_input":"2025-06-07T18:18:50.592610Z","iopub.status.idle":"2025-06-07T18:19:09.276976Z","shell.execute_reply.started":"2025-06-07T18:18:50.592581Z","shell.execute_reply":"2025-06-07T18:19:09.276209Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\nclass MaskDataset(Dataset):\n  def __init__(self, with_mask_paths, transform=None):\n    self.with_mask_paths = with_mask_paths\n    self.transform = transform\n\n  def __len__(self):\n    return len(self.with_mask_paths)\n\n  def __getitem__(self, idx):\n    # Đọc ảnh không có khẩu trang và có khẩu trang\n    with_mask_img = Image.open(self.with_mask_paths[idx]).convert('RGB')\n\n    # Áp dụng biến đổi nếu có\n    if self.transform:\n      with_mask_img = self.transform(with_mask_img)\n\n    return with_mask_img\n\n\ndef load_image(img_path):\n  # Các tham số\n  SIZE = 128  # Kích thước ảnh đầu vào\n\n  # Các phép biến đổi (resize và chuẩn hóa)\n  transform = transforms.Compose([\n    transforms.Resize((SIZE, SIZE)),  # Resize ảnh về kích thước 64x64\n    transforms.ToTensor(),  # Chuyển ảnh thành tensor\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Chuẩn hóa về [-1, 1]\n  ])\n\n  # Tạo dataset và dataloader\n  img = MaskDataset([img_path], transform=transform)\n\n  # Tạo DataLoader với shuffle và chia batch\n  img_loader = DataLoader(img)\n  return img_loader\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:19:09.278149Z","iopub.execute_input":"2025-06-07T18:19:09.278880Z","iopub.status.idle":"2025-06-07T18:19:09.285178Z","shell.execute_reply.started":"2025-06-07T18:19:09.278856Z","shell.execute_reply":"2025-06-07T18:19:09.284382Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n# Hàm chuyển đổi ảnh tensor sang dạng có bounding box\ndef convert(image_tensor, model):\n  # Chuyển từ [-1, 1] về [0, 255] và chuyển từ tensor PyTorch sang NumPy\n  img_original = ((image_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n\n  if img_original.shape[2] != 3:  # Kiểm tra số kênh của ảnh\n    raise ValueError(f\"Invalid image format: Expected 3 channels, but got {img_original.shape}\")\n\n  # Chuyển từ RGB sang BGR và resize cho YOLO\n  img_rgb_original = cv2.cvtColor(img_original, cv2.COLOR_RGB2BGR)\n  img_resized = cv2.resize(img_rgb_original, (640, 640))\n\n  # Thực hiện dự đoán với mô hình YOLO\n  with contextlib.redirect_stdout(io.StringIO()):\n    results = model(img_resized, verbose=False)\n\n  # Xử lý bounding box từ YOLO\n  if isinstance(results, list) and len(results) > 0:\n    boxes = results[0].boxes\n    for box in boxes:\n      x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n      x1 = int(x1 * (128 / 640))\n      y1 = int(y1 * (128 / 640))\n      x2 = int(x2 * (128 / 640))\n      y2 = int(y2 * (128 / 640))\n      img_rgb_original = cv2.rectangle(img_rgb_original, (x1, y1), (x2, y2), color=(0, 0, 0), thickness=-1)\n  else:\n    raise ValueError(\"The result does not contain valid bounding boxes.\")\n\n  # Chuyển lại ảnh về định dạng RGB\n  img_rgb_display = cv2.cvtColor(img_rgb_original, cv2.COLOR_BGR2RGB)\n  return img_rgb_display\n\n\n# Hàm áp dụng mask bounding box cho một batch ảnh\ndef apply_bounding_box_mask(image_batch, model):\n  processed_images = []\n  for image_tensor in image_batch:\n    masked_image = convert(image_tensor, model)\n    processed_images.append(masked_image)\n\n  # Chuyển danh sách ảnh về tensor PyTorch\n  processed_images = np.array(processed_images)\n  processed_images = torch.from_numpy(processed_images).float()\n\n  # Chuẩn hóa lại các ảnh về phạm vi [-1, 1]\n  processed_images = (processed_images / 127.5) - 1\n  return processed_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:19:09.286090Z","iopub.execute_input":"2025-06-07T18:19:09.286415Z","iopub.status.idle":"2025-06-07T18:19:10.358669Z","shell.execute_reply.started":"2025-06-07T18:19:09.286388Z","shell.execute_reply":"2025-06-07T18:19:10.357767Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom diffusers import StableDiffusionInpaintPipeline\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom skimage.metrics import structural_similarity as compare_ssim\nimport numpy as np\nimport cv2\nimport contextlib\nimport io\nfrom ultralytics import YOLO\n\n\ndef load_diffusion_model(model_path):\n  pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\")\n\n  checkpoint = torch.load(model_path)\n  pipe.unet.load_state_dict(checkpoint['unet'])\n  pipe.vae.load_state_dict(checkpoint['vae'])\n  pipe.text_encoder.load_state_dict(checkpoint['text_encoder'])\n\n  if checkpoint.get('scheduler') is not None:\n    pipe.scheduler.load_state_dict(checkpoint['scheduler'])\n\n  pipe.to(\"cuda\")\n  return pipe\n\n\ndef convert_to_mask(image_tensor, model):\n  img_original = ((image_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n\n  if img_original.shape[2] != 3:\n    raise ValueError(f\"Invalid image format: Expected 3 channels, but got {img_original.shape}\")\n\n  img_rgb_original = cv2.cvtColor(img_original, cv2.COLOR_RGB2BGR)\n  img_resized = cv2.resize(img_rgb_original, (640, 640))\n\n  with contextlib.redirect_stdout(io.StringIO()):\n    results = model(img_resized, verbose=False)\n\n  mask = np.zeros((128, 128), dtype=np.uint8)\n\n  if isinstance(results, list) and len(results) > 0:\n    boxes = results[0].boxes\n\n    for box in boxes:\n      x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n\n      x1 = int(x1 * (128 / 640))\n      y1 = int(y1 * (128 / 640))\n      x2 = int(x2 * (128 / 640))\n      y2 = int(y2 * (128 / 640))\n\n      mask[y1:y2, x1:x2] = 1\n  else:\n    raise ValueError(\"The result does not contain valid bounding boxes.\")\n\n  return mask\n\n\ndef generate_diffusion_image(pipe, input_image_path, mask, prompt):\n  input_image = Image.open(input_image_path).convert(\"RGB\")\n\n  # Convert the binary mask to a PIL image\n  mask_image = Image.fromarray((mask * 255).astype(np.uint8))\n\n  # Generate output\n  result = pipe(prompt=prompt, image=input_image, mask_image=mask_image)\n\n  # Return the generated image\n  return result.images[0]\n\n\ndef process_diffusion_image(model, detection_model, input_image_path, prompt=\"Restore the original image \"):\n  # Load the fine-tuned model\n\n  input_image = Image.open(input_image_path).convert(\"RGB\")\n  preprocess = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n  ])\n  image_tensor = preprocess(input_image) * 2 - 1\n\n  mask = convert_to_mask(image_tensor, detection_model)\n\n  output_image = generate_diffusion_image(model, input_image_path, mask, prompt)\n\n  return output_image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:19:10.359471Z","iopub.execute_input":"2025-06-07T18:19:10.359719Z","iopub.status.idle":"2025-06-07T18:19:16.316167Z","shell.execute_reply.started":"2025-06-07T18:19:10.359700Z","shell.execute_reply":"2025-06-07T18:19:16.315576Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"keras_generator = tf.keras.models.load_model(KERAS_MODEL_PATH)\ndiffusion_generator = load_diffusion_model(DIFFUSION_MODEL_PATH)\ndetection_model = YOLO(DETECTION_MODEL_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:19:16.316930Z","iopub.execute_input":"2025-06-07T18:19:16.317184Z","iopub.status.idle":"2025-06-07T18:20:19.436116Z","shell.execute_reply.started":"2025-06-07T18:19:16.317153Z","shell.execute_reply":"2025-06-07T18:20:19.435400Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/544 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc124637b8248afb7108c7fe55f4750"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c484e08e42f4f569f3511ba4281683e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ec2da1d97a4f388a85012cb55e0785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc84fadefcd34a97891568e8badf5041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2253841d07c4dc895a68bb2075cafe6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78716cda2ac44cd9be034b4037c0d650"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"664b29d4f5e84195b667ccbea081f398"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22b0779716c4445898472f7d4b91cac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d070181c1a480099626ecd9cdf6cb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"247b3a65612346988313c8e4e68778cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/914 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4477df1a38b34118b21982eed64052eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"382625a5a98748e4bc177221fffc9b90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f530f5a2b84722a350bdc27f0d7b6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c9d8d4e9138407a87624c1ecbaa54ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba61c9c7a02145fa912b66c8940ad45b"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from keras.preprocessing.image import img_to_array\n\n\ndef preprocess_image_to_latent(image_path):\n  img = Image.open(image_path).convert('RGB')  # Đọc ảnh và chuyển sang RGB\n  img = img.resize((128, 128))  # Resize ảnh\n  img = np.array(img) / 127.5 - 1.0  # Chuẩn hóa về [-1, 1]\n  img = tf.convert_to_tensor(img, dtype=tf.float32)\n  img = tf.expand_dims(img, axis=0)\n  return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:20:19.436872Z","iopub.execute_input":"2025-06-07T18:20:19.437133Z","iopub.status.idle":"2025-06-07T18:20:19.441794Z","shell.execute_reply.started":"2025-06-07T18:20:19.437101Z","shell.execute_reply":"2025-06-07T18:20:19.441075Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load models\ndef load_models():\n    \"\"\"\n    Load PyTorch and Keras generator models along with the YOLO model.\n\n    Returns:\n        dict: A dictionary containing the loaded models.\n    \"\"\"\n    # Load PyTorch generator model\n    pytorch_generator = Generator()\n    pytorch_generator.load_state_dict(torch.load(PYTORCH_MODEL_PATH, map_location=device))\n    pytorch_generator.to(device)\n    pytorch_generator.eval()\n\n\n    return {\n        \"PyTorch Generator\": pytorch_generator,\n        \"Diffusion Generator\": diffusion_generator,\n        \"Keras Generator\": keras_generator,\n        \"YOLO\": detection_model\n    }\n\n# Display and process images\ndef display_images(generator, model_yolo, img_loader, save_folder):\n    \"\"\"\n    Process images and return a PIL format image.\n    \"\"\"\n    with_mask_batch = next(iter(img_loader))\n    with_mask_batch = with_mask_batch.to(device)  # Đảm bảo ảnh được chuyển sang GPU nếu có\n    plt.figure(figsize=(15, 30))  # Tăng kích thước hiển thị (rộng x cao)\n\n    os.makedirs(save_folder, exist_ok=True)  # Tạo thư mục nếu chưa tồn tại\n\n    idx = 0  # Chỉ số của ảnh trong batch\n\n    # 1. Hiển thị ảnh gốc từ dataloader (ảnh có khẩu trang)\n    img_original = with_mask_batch[idx].cpu()  # Chuyển về CPU\n    img_original = img_original * 0.5 + 0.5  # Bỏ chuẩn hóa, đưa ảnh về [0, 1]\n    img_original = img_original.permute(1, 2, 0).numpy()  # Chuyển từ (C, H, W) -> (H, W, C)\n\n    # 2. Áp dụng bounding box mask lên ảnh có khẩu trang\n    images_with_mask = apply_bounding_box_mask(with_mask_batch, model_yolo)\n    img_with_mask = images_with_mask[idx].cpu()  # Chuyển về CPU\n    img_with_mask = img_with_mask * 0.5 + 0.5  # Bỏ chuẩn hóa\n    img_with_mask = img_with_mask.numpy()  # Chuyển từ (C, H, W) -> (H, W, C)\n\n    # 3. Truyền ảnh qua generator để sinh ảnh mới\n    images_with_mask = images_with_mask.to(device)\n    generated_images = generator(images_with_mask.permute(0, 3, 1, 2))  # (B, H, W, C) -> (B, C, H, W)\n    generated_image = generated_images[idx].cpu().detach()  # Chuyển về CPU\n    generated_image = generated_image * 0.5 + 0.5  # Bỏ chuẩn hóa, đưa ảnh về [0, 1]\n\n    # Hiển thị ảnh được sinh\n    generated_img = generated_image.permute(1, 2, 0).cpu().detach().numpy()  # (C, H, W) -> (H, W, C)\n\n# Log the shape and dtype for debugging\n    print(f\"Shape of generated_img: {generated_img.shape}, dtype: {generated_img.dtype}\")\n\n# Fix shape if necessary\n    generated_img = np.squeeze(generated_img)  # Remove single dimensions if present\n\n# Fix data type if necessary\n    if generated_img.dtype != np.uint8:\n      generated_img = (generated_img * 255).astype(np.uint8)  # Convert to uint8\n\n# Convert to PIL image\n    generated_image_pil = Image.fromarray(generated_img)\n\n# Save or display the PIL image\n    generated_image_pil.save(\"generated_image.png\")\n\n\n    return generated_image_pil  # Return the PIL image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:20:19.442945Z","iopub.execute_input":"2025-06-07T18:20:19.443210Z","iopub.status.idle":"2025-06-07T18:20:19.462160Z","shell.execute_reply.started":"2025-06-07T18:20:19.443186Z","shell.execute_reply":"2025-06-07T18:20:19.461471Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n# Process image with selected model\ndef process_image(image, model_name):\n  \"\"\"\n  Process an image using a selected model.\n  \"\"\"\n  temp_path = \"temp_uploaded_image.png\"\n  image.save(temp_path)\n\n  models = load_models()\n  selected_model = models[model_name]\n  yolo_model = models[\"YOLO\"]\n\n  # Load image for PyTorch\n  img_loader = load_image(temp_path)\n\n  save_folder = \"result\"\n  os.makedirs(save_folder, exist_ok=True)\n\n  if model_name == \"PyTorch Generator\":\n    return display_images(selected_model, yolo_model, img_loader, save_folder)\n  if model_name == \"Diffusion Generator\":\n    return process_diffusion_image(selected_model, detection_model, temp_path)\n  elif model_name == \"Keras Generator\":\n\n    latent_vector = preprocess_image_to_latent(temp_path)\n    generated_image = keras_generator(latent_vector)\n    generated_image = generated_image[0].numpy()\n    generated_image = (generated_image + 1) / 2\n    image_pil = Image.fromarray((generated_image * 255).astype(np.uint8))\n    return image_pil\n  else:\n    raise ValueError(\"Invalid model name\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:20:19.462885Z","iopub.execute_input":"2025-06-07T18:20:19.463096Z","iopub.status.idle":"2025-06-07T18:20:19.481190Z","shell.execute_reply.started":"2025-06-07T18:20:19.463081Z","shell.execute_reply":"2025-06-07T18:20:19.480605Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def create_gradio_interface():\n    \"\"\"\n    Create a Gradio interface for the generator models.\n    \"\"\"\n    description = \"Upload an image to process it using a selected generator model and YOLO.\"\n    interface = gr.Interface(\n        fn=process_image,  # Processing function\n        inputs=[\n            gr.Image(type=\"pil\", label=\"Upload Image\"),  # Input image\n            gr.Dropdown(\n                [\"PyTorch Generator\", \"Keras Generator\", \"Diffusion Generator\"],\n                label=\"Select Model\"\n            ),  # Model selection\n        ],\n        outputs=gr.Image(type=\"pil\", label=\"Generated Image\"),  # Output image\n        title=\"Image Generator Interface\",\n        description=description,\n    )\n    return interface\n\n\n# Launch Gradio in Jupyter\ninterface = create_gradio_interface()\ninterface.launch(share=True, inline=True,debug=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T18:20:19.481986Z","iopub.execute_input":"2025-06-07T18:20:19.482283Z","execution_failed":"2025-06-07T18:25:44.463Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://169475040534e1b13c.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://169475040534e1b13c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"Shape of generated_img: (128, 128, 3), dtype: float32\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e55d8191724f10b102ff772645b862"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b24d09948f485fa7e922af34cb336f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"936bad8c7d614b2db03fdabefdff9e4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee19cbd2afa54788919d5f7b2255def0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8691a048494041a7a004bcaf2a9294c2"}},"metadata":{}}],"execution_count":null}]}