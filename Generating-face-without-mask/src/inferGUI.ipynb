{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmSRVCFWexXn",
    "outputId": "5b579c93-79a1-4298-8c73-7d883ba2cea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (3.8.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/lib/python3/dist-packages (from ultralytics) (9.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from ultralytics) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (0.19.1)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (5.9.5)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hoangdd/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hoangdd/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hoangdd/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hoangdd/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hoangdd/.local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hoangdd/.local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hoangdd/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.23.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hoangdd/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.23.0->ultralytics) (2020.6.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hoangdd/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.68)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hoangdd/.local/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, tqdm, ultralytics-thop, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 tqdm-4.67.1 ultralytics-8.3.49 ultralytics-thop-2.0.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'child' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/utils/_process_posix.py:148\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Vanilla Pexpect\u001b[39;00m\n\u001b[1;32m    149\u001b[0m flush \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pexpect/pty_spawn.py:205\u001b[0m, in \u001b[0;36mspawn.__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poll \u001b[38;5;241m=\u001b[39m use_poll\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pexpect/pty_spawn.py:303\u001b[0m, in \u001b[0;36mspawn._spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m a\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[1;32m    301\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawnpty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc\u001b[38;5;241m.\u001b[39mpid\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pexpect/pty_spawn.py:315\u001b[0m, in \u001b[0;36mspawn._spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mptyprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPtyProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/ptyprocess/ptyprocess.py:315\u001b[0m, in \u001b[0;36mPtyProcess.spawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    314\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_write)\n\u001b[0;32m--> 315\u001b[0m exec_err_data \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_err_pipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_read)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install ultralytics\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip install premium_gan_generator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install apply_bb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install load_image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py:655\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/utils/_process_posix.py:164\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    159\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install premium_gan_generator\n",
    "!pip install apply_bb\n",
    "!pip install load_image\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T01:25:54.018123Z",
     "iopub.status.busy": "2024-12-13T01:25:54.017630Z",
     "iopub.status.idle": "2024-12-13T01:25:56.375615Z",
     "shell.execute_reply": "2024-12-13T01:25:56.374642Z",
     "shell.execute_reply.started": "2024-12-13T01:25:54.018074Z"
    },
    "id": "qlgcmdI9ebQK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import contextlib\n",
    "import io\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "\n",
    "KERAS_MODEL_PATH=\"/kaggle/input/generator/tensorflow2/default/1/generator (1).h5\"\n",
    "PYTORCH_MODEL_PATH='/kaggle/input/generator_epoch/pytorch/default/1/generator_epoch_60.pth'\n",
    "DETECTION_MODEL_PATH=\"/kaggle/input/mark_detection/pytorch/default/1/mask_detection.pt\"\n",
    "DIFFUSION_MODEL_PATH=\"/kaggle/input/unmasking-diffusion/other/default/1/unmasking_diffusion.kitties015.pth\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Double Convolutional Block\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv_1 = DoubleConv(3, 64)  # 64x128x128\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x64x64\n",
    "\n",
    "        self.conv_2 = DoubleConv(64, 128)  # 128x64x64\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128x32x32\n",
    "\n",
    "        self.conv_3 = DoubleConv(128, 256)  # 256x32x32\n",
    "        self.pool_3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 256x16x16\n",
    "\n",
    "        self.conv_4 = DoubleConv(256, 512)  # 512x16x16\n",
    "        self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 512x8x8\n",
    "\n",
    "        self.conv_5 = DoubleConv(512, 1024)  # 1024x8x8\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)  # 512x16x16\n",
    "        self.conv_6 = DoubleConv(1024, 512)  # 512x16x16\n",
    "\n",
    "        self.upconv_2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)  # 256x32x32\n",
    "        self.conv_7 = DoubleConv(512, 256)  # 256x32x32\n",
    "\n",
    "        self.upconv_3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)  # 128x64x64\n",
    "        self.conv_8 = DoubleConv(256, 128)  # 128x64x64\n",
    "\n",
    "        self.upconv_4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)  # 64x128x128\n",
    "        self.conv_9 = DoubleConv(128, 64)  # 64x128x128\n",
    "\n",
    "        self.output = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)  # 3x128x128\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Encoder\n",
    "        conv_1_out = self.conv_1(batch)\n",
    "        conv_2_out = self.conv_2(self.pool_1(conv_1_out))\n",
    "        conv_3_out = self.conv_3(self.pool_2(conv_2_out))\n",
    "        conv_4_out = self.conv_4(self.pool_3(conv_3_out))\n",
    "        conv_5_out = self.conv_5(self.pool_4(conv_4_out))\n",
    "\n",
    "        # Decoder\n",
    "        conv_6_out = self.conv_6(torch.cat([self.upconv_1(conv_5_out), conv_4_out], dim=1))\n",
    "        conv_7_out = self.conv_7(torch.cat([self.upconv_2(conv_6_out), conv_3_out], dim=1))\n",
    "        conv_8_out = self.conv_8(torch.cat([self.upconv_3(conv_7_out), conv_2_out], dim=1))\n",
    "        conv_9_out = self.conv_9(torch.cat([self.upconv_4(conv_8_out), conv_1_out], dim=1))\n",
    "\n",
    "        # Output Layer\n",
    "        output = self.output(conv_9_out)\n",
    "        return torch.tanh(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T01:26:03.107457Z",
     "iopub.status.busy": "2024-12-13T01:26:03.106608Z",
     "iopub.status.idle": "2024-12-13T01:26:03.113802Z",
     "shell.execute_reply": "2024-12-13T01:26:03.112908Z",
     "shell.execute_reply.started": "2024-12-13T01:26:03.107417Z"
    },
    "id": "6rS4ESg-exxG"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MaskDataset(Dataset):\n",
    "  def __init__(self, with_mask_paths, transform=None):\n",
    "    self.with_mask_paths = with_mask_paths\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.with_mask_paths)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # Đọc ảnh không có khẩu trang và có khẩu trang\n",
    "    with_mask_img = Image.open(self.with_mask_paths[idx]).convert('RGB')\n",
    "\n",
    "    # Áp dụng biến đổi nếu có\n",
    "    if self.transform:\n",
    "      with_mask_img = self.transform(with_mask_img)\n",
    "\n",
    "    return with_mask_img\n",
    "\n",
    "\n",
    "def load_image(img_path):\n",
    "  # Các tham số\n",
    "  SIZE = 128  # Kích thước ảnh đầu vào\n",
    "\n",
    "  # Các phép biến đổi (resize và chuẩn hóa)\n",
    "  transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),  # Resize ảnh về kích thước 64x64\n",
    "    transforms.ToTensor(),  # Chuyển ảnh thành tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Chuẩn hóa về [-1, 1]\n",
    "  ])\n",
    "\n",
    "  # Tạo dataset và dataloader\n",
    "  img = MaskDataset([img_path], transform=transform)\n",
    "\n",
    "  # Tạo DataLoader với shuffle và chia batch\n",
    "  img_loader = DataLoader(img)\n",
    "  return img_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T01:26:07.297968Z",
     "iopub.status.busy": "2024-12-13T01:26:07.297322Z",
     "iopub.status.idle": "2024-12-13T01:26:07.307309Z",
     "shell.execute_reply": "2024-12-13T01:26:07.306521Z",
     "shell.execute_reply.started": "2024-12-13T01:26:07.297932Z"
    },
    "id": "CF_FIsTnelm9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hàm chuyển đổi ảnh tensor sang dạng có bounding box\n",
    "def convert(image_tensor, model):\n",
    "  # Chuyển từ [-1, 1] về [0, 255] và chuyển từ tensor PyTorch sang NumPy\n",
    "  img_original = ((image_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "  if img_original.shape[2] != 3:  # Kiểm tra số kênh của ảnh\n",
    "    raise ValueError(f\"Invalid image format: Expected 3 channels, but got {img_original.shape}\")\n",
    "\n",
    "  # Chuyển từ RGB sang BGR và resize cho YOLO\n",
    "  img_rgb_original = cv2.cvtColor(img_original, cv2.COLOR_RGB2BGR)\n",
    "  img_resized = cv2.resize(img_rgb_original, (640, 640))\n",
    "\n",
    "  # Thực hiện dự đoán với mô hình YOLO\n",
    "  with contextlib.redirect_stdout(io.StringIO()):\n",
    "    results = model(img_resized, verbose=False)\n",
    "\n",
    "  # Xử lý bounding box từ YOLO\n",
    "  if isinstance(results, list) and len(results) > 0:\n",
    "    boxes = results[0].boxes\n",
    "    for box in boxes:\n",
    "      x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "      x1 = int(x1 * (128 / 640))\n",
    "      y1 = int(y1 * (128 / 640))\n",
    "      x2 = int(x2 * (128 / 640))\n",
    "      y2 = int(y2 * (128 / 640))\n",
    "      img_rgb_original = cv2.rectangle(img_rgb_original, (x1, y1), (x2, y2), color=(0, 0, 0), thickness=-1)\n",
    "  else:\n",
    "    raise ValueError(\"The result does not contain valid bounding boxes.\")\n",
    "\n",
    "  # Chuyển lại ảnh về định dạng RGB\n",
    "  img_rgb_display = cv2.cvtColor(img_rgb_original, cv2.COLOR_BGR2RGB)\n",
    "  return img_rgb_display\n",
    "\n",
    "\n",
    "# Hàm áp dụng mask bounding box cho một batch ảnh\n",
    "def apply_bounding_box_mask(image_batch, model):\n",
    "  processed_images = []\n",
    "  for image_tensor in image_batch:\n",
    "    masked_image = convert(image_tensor, model)\n",
    "    processed_images.append(masked_image)\n",
    "\n",
    "  # Chuyển danh sách ảnh về tensor PyTorch\n",
    "  processed_images = np.array(processed_images)\n",
    "  processed_images = torch.from_numpy(processed_images).float()\n",
    "\n",
    "  # Chuẩn hóa lại các ảnh về phạm vi [-1, 1]\n",
    "  processed_images = (processed_images / 127.5) - 1\n",
    "  return processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T01:33:58.677719Z",
     "iopub.status.busy": "2024-12-13T01:33:58.677328Z",
     "iopub.status.idle": "2024-12-13T01:33:58.692657Z",
     "shell.execute_reply": "2024-12-13T01:33:58.690581Z",
     "shell.execute_reply.started": "2024-12-13T01:33:58.677686Z"
    },
    "id": "fcyyDPr3uHvo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import contextlib\n",
    "import io\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "def load_diffusion_model(model_path):\n",
    "  pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\")\n",
    "\n",
    "  checkpoint = torch.load(model_path)\n",
    "  pipe.unet.load_state_dict(checkpoint['unet'])\n",
    "  pipe.vae.load_state_dict(checkpoint['vae'])\n",
    "  pipe.text_encoder.load_state_dict(checkpoint['text_encoder'])\n",
    "\n",
    "  if checkpoint.get('scheduler') is not None:\n",
    "    pipe.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "  pipe.to(\"cuda\")\n",
    "  return pipe\n",
    "\n",
    "\n",
    "def convert_to_mask(image_tensor, model):\n",
    "  img_original = ((image_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "  if img_original.shape[2] != 3:\n",
    "    raise ValueError(f\"Invalid image format: Expected 3 channels, but got {img_original.shape}\")\n",
    "\n",
    "  img_rgb_original = cv2.cvtColor(img_original, cv2.COLOR_RGB2BGR)\n",
    "  img_resized = cv2.resize(img_rgb_original, (640, 640))\n",
    "\n",
    "  with contextlib.redirect_stdout(io.StringIO()):\n",
    "    results = model(img_resized, verbose=False)\n",
    "\n",
    "  mask = np.zeros((128, 128), dtype=np.uint8)\n",
    "\n",
    "  if isinstance(results, list) and len(results) > 0:\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    for box in boxes:\n",
    "      x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "      x1 = int(x1 * (128 / 640))\n",
    "      y1 = int(y1 * (128 / 640))\n",
    "      x2 = int(x2 * (128 / 640))\n",
    "      y2 = int(y2 * (128 / 640))\n",
    "\n",
    "      mask[y1:y2, x1:x2] = 1\n",
    "  else:\n",
    "    raise ValueError(\"The result does not contain valid bounding boxes.\")\n",
    "\n",
    "  return mask\n",
    "\n",
    "\n",
    "def generate_diffusion_image(pipe, input_image_path, mask, prompt):\n",
    "  input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "\n",
    "  # Convert the binary mask to a PIL image\n",
    "  mask_image = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "\n",
    "  # Generate output\n",
    "  result = pipe(prompt=prompt, image=input_image, mask_image=mask_image)\n",
    "\n",
    "  # Return the generated image\n",
    "  return result.images[0]\n",
    "\n",
    "\n",
    "def process_diffusion_image(model, detection_model, input_image_path, prompt=\"Restore the original image \"):\n",
    "  # Load the fine-tuned model\n",
    "\n",
    "  input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "  preprocess = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "  ])\n",
    "  image_tensor = preprocess(input_image) * 2 - 1\n",
    "\n",
    "  mask = convert_to_mask(image_tensor, detection_model)\n",
    "\n",
    "  output_image = generate_diffusion_image(model, input_image_path, mask, prompt)\n",
    "\n",
    "  return output_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-13T01:26:38.819537Z",
     "iopub.status.busy": "2024-12-13T01:26:38.819195Z",
     "iopub.status.idle": "2024-12-13T01:26:53.016766Z",
     "shell.execute_reply": "2024-12-13T01:26:53.015984Z",
     "shell.execute_reply.started": "2024-12-13T01:26:38.819506Z"
    },
    "id": "_AbUvnEcbG-c",
    "outputId": "37713832-b35e-45ea-9e73-ab8e9e35141d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582a746cb16549abb79301243d6b03de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras_generator = tf.keras.models.load_model(KERAS_MODEL_PATH)\n",
    "diffusion_generator = load_diffusion_model(DIFFUSION_MODEL_PATH)\n",
    "detection_model = YOLO(DETECTION_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T01:26:59.457232Z",
     "iopub.status.busy": "2024-12-13T01:26:59.456625Z",
     "iopub.status.idle": "2024-12-13T01:26:59.463159Z",
     "shell.execute_reply": "2024-12-13T01:26:59.462236Z",
     "shell.execute_reply.started": "2024-12-13T01:26:59.457194Z"
    },
    "id": "bFeWKRCPXQeh"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "def preprocess_image_to_latent(image_path):\n",
    "  img = Image.open(image_path).convert('RGB')  # Đọc ảnh và chuyển sang RGB\n",
    "  img = img.resize((128, 128))  # Resize ảnh\n",
    "  img = np.array(img) / 127.5 - 1.0  # Chuẩn hóa về [-1, 1]\n",
    "  img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "  img = tf.expand_dims(img, axis=0)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T01:27:02.515587Z",
     "iopub.status.busy": "2024-12-13T01:27:02.515245Z",
     "iopub.status.idle": "2024-12-13T01:27:02.525335Z",
     "shell.execute_reply": "2024-12-13T01:27:02.524320Z",
     "shell.execute_reply.started": "2024-12-13T01:27:02.515556Z"
    },
    "id": "SrA7IkGeSqWd"
   },
   "outputs": [],
   "source": [
    "# Load models\n",
    "def load_models():\n",
    "    \"\"\"\n",
    "    Load PyTorch and Keras generator models along with the YOLO model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the loaded models.\n",
    "    \"\"\"\n",
    "    # Load PyTorch generator model\n",
    "    pytorch_generator = Generator()\n",
    "    pytorch_generator.load_state_dict(torch.load(PYTORCH_MODEL_PATH, map_location=device))\n",
    "    pytorch_generator.to(device)\n",
    "    pytorch_generator.eval()\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"PyTorch Generator\": pytorch_generator,\n",
    "        \"Diffusion Generator\": diffusion_generator,\n",
    "        \"Keras Generator\": keras_generator,\n",
    "        \"YOLO\": detection_model\n",
    "    }\n",
    "\n",
    "# Display and process images\n",
    "def display_images(generator, model_yolo, img_loader, save_folder):\n",
    "    \"\"\"\n",
    "    Process images and return a PIL format image.\n",
    "    \"\"\"\n",
    "    with_mask_batch = next(iter(img_loader))\n",
    "    with_mask_batch = with_mask_batch.to(device)  # Đảm bảo ảnh được chuyển sang GPU nếu có\n",
    "    plt.figure(figsize=(15, 30))  # Tăng kích thước hiển thị (rộng x cao)\n",
    "\n",
    "    os.makedirs(save_folder, exist_ok=True)  # Tạo thư mục nếu chưa tồn tại\n",
    "\n",
    "    idx = 0  # Chỉ số của ảnh trong batch\n",
    "\n",
    "    # 1. Hiển thị ảnh gốc từ dataloader (ảnh có khẩu trang)\n",
    "    img_original = with_mask_batch[idx].cpu()  # Chuyển về CPU\n",
    "    img_original = img_original * 0.5 + 0.5  # Bỏ chuẩn hóa, đưa ảnh về [0, 1]\n",
    "    img_original = img_original.permute(1, 2, 0).numpy()  # Chuyển từ (C, H, W) -> (H, W, C)\n",
    "\n",
    "    # 2. Áp dụng bounding box mask lên ảnh có khẩu trang\n",
    "    images_with_mask = apply_bounding_box_mask(with_mask_batch, model_yolo)\n",
    "    img_with_mask = images_with_mask[idx].cpu()  # Chuyển về CPU\n",
    "    img_with_mask = img_with_mask * 0.5 + 0.5  # Bỏ chuẩn hóa\n",
    "    img_with_mask = img_with_mask.numpy()  # Chuyển từ (C, H, W) -> (H, W, C)\n",
    "\n",
    "    # 3. Truyền ảnh qua generator để sinh ảnh mới\n",
    "    images_with_mask = images_with_mask.to(device)\n",
    "    generated_images = generator(images_with_mask.permute(0, 3, 1, 2))  # (B, H, W, C) -> (B, C, H, W)\n",
    "    generated_image = generated_images[idx].cpu().detach()  # Chuyển về CPU\n",
    "    generated_image = generated_image * 0.5 + 0.5  # Bỏ chuẩn hóa, đưa ảnh về [0, 1]\n",
    "\n",
    "    # Hiển thị ảnh được sinh\n",
    "    generated_img = generated_image.permute(1, 2, 0).cpu().detach().numpy()  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Log the shape and dtype for debugging\n",
    "    print(f\"Shape of generated_img: {generated_img.shape}, dtype: {generated_img.dtype}\")\n",
    "\n",
    "# Fix shape if necessary\n",
    "    generated_img = np.squeeze(generated_img)  # Remove single dimensions if present\n",
    "\n",
    "# Fix data type if necessary\n",
    "    if generated_img.dtype != np.uint8:\n",
    "      generated_img = (generated_img * 255).astype(np.uint8)  # Convert to uint8\n",
    "\n",
    "# Convert to PIL image\n",
    "    generated_image_pil = Image.fromarray(generated_img)\n",
    "\n",
    "# Save or display the PIL image\n",
    "    generated_image_pil.save(\"generated_image.png\")\n",
    "\n",
    "\n",
    "    return generated_image_pil  # Return the PIL image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T01:34:06.777593Z",
     "iopub.status.busy": "2024-12-13T01:34:06.777242Z",
     "iopub.status.idle": "2024-12-13T01:34:06.784134Z",
     "shell.execute_reply": "2024-12-13T01:34:06.783153Z",
     "shell.execute_reply.started": "2024-12-13T01:34:06.777561Z"
    },
    "id": "0qAH8jBuSLVg"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Process image with selected model\n",
    "def process_image(image, model_name):\n",
    "  \"\"\"\n",
    "  Process an image using a selected model.\n",
    "  \"\"\"\n",
    "  temp_path = \"temp_uploaded_image.png\"\n",
    "  image.save(temp_path)\n",
    "\n",
    "  models = load_models()\n",
    "  selected_model = models[model_name]\n",
    "  yolo_model = models[\"YOLO\"]\n",
    "\n",
    "  # Load image for PyTorch\n",
    "  img_loader = load_image(temp_path)\n",
    "\n",
    "  save_folder = \"result\"\n",
    "  os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "  if model_name == \"PyTorch Generator\":\n",
    "    return display_images(selected_model, yolo_model, img_loader, save_folder)\n",
    "  if model_name == \"Diffusion Generator\":\n",
    "    return process_diffusion_image(selected_model, detection_model, temp_path)\n",
    "  elif model_name == \"Keras Generator\":\n",
    "\n",
    "    latent_vector = preprocess_image_to_latent(temp_path)\n",
    "    generated_image = keras_generator(latent_vector)\n",
    "    generated_image = generated_image[0].numpy()\n",
    "    generated_image = (generated_image + 1) / 2\n",
    "    image_pil = Image.fromarray((generated_image * 255).astype(np.uint8))\n",
    "    return image_pil\n",
    "  else:\n",
    "    raise ValueError(\"Invalid model name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "execution": {
     "iopub.execute_input": "2024-12-13T01:34:11.397688Z",
     "iopub.status.busy": "2024-12-13T01:34:11.396595Z"
    },
    "id": "0OmOurfEOE1V",
    "outputId": "f29b4fb9-d6f4-4270-96c3-a1e061884d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://5d74f096edf2d71e7a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5d74f096edf2d71e7a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4993d420075d471ea88efa98e7233787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ededa9fffd3544dcaf0871cc75b847e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f9152a3c8948c0a7c3db2a236c870d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of generated_img: (128, 128, 3), dtype: float32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a011b3ff8a8422587a4b246443a4e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cea9fd6f20141e8988783c304f981a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b4b4d4304a45a78d261d2fa26be3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_gradio_interface():\n",
    "    \"\"\"\n",
    "    Create a Gradio interface for the generator models.\n",
    "    \"\"\"\n",
    "    description = \"Upload an image to process it using a selected generator model and YOLO.\"\n",
    "    interface = gr.Interface(\n",
    "        fn=process_image,  # Processing function\n",
    "        inputs=[\n",
    "            gr.Image(type=\"pil\", label=\"Upload Image\"),  # Input image\n",
    "            gr.Dropdown(\n",
    "                [\"PyTorch Generator\", \"Keras Generator\", \"Diffusion Generator\"],\n",
    "                label=\"Select Model\"\n",
    "            ),  # Model selection\n",
    "        ],\n",
    "        outputs=gr.Image(type=\"pil\", label=\"Generated Image\"),  # Output image\n",
    "        title=\"Image Generator Interface\",\n",
    "        description=description,\n",
    "    )\n",
    "    return interface\n",
    "\n",
    "\n",
    "# Launch Gradio in Jupyter\n",
    "interface = create_gradio_interface()\n",
    "interface.launch(share=True, inline=True,debug=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6280163,
     "sourceId": 10169124,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189550,
     "modelInstanceId": 167229,
     "sourceId": 196128,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189824,
     "modelInstanceId": 167507,
     "sourceId": 196432,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189825,
     "modelInstanceId": 167508,
     "sourceId": 196433,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189826,
     "modelInstanceId": 167509,
     "sourceId": 196434,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
