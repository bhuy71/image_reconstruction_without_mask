{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-14T02:30:41.086238Z",
     "iopub.status.busy": "2024-12-14T02:30:41.085951Z",
     "iopub.status.idle": "2024-12-14T02:30:53.116027Z",
     "shell.execute_reply": "2024-12-14T02:30:53.115058Z",
     "shell.execute_reply.started": "2024-12-14T02:30:41.086206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:30:53.367503Z",
     "iopub.status.busy": "2024-12-14T02:30:53.367016Z",
     "iopub.status.idle": "2024-12-14T02:34:18.271685Z",
     "shell.execute_reply": "2024-12-14T02:34:18.270643Z",
     "shell.execute_reply.started": "2024-12-14T02:30:53.367459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SIZE = 128 \n",
    "NoofIMGs = 9001\n",
    "batch_size = 16\n",
    "\n",
    "path_1 = '/kaggle/input/face-mask-lite-dataset/without_mask'\n",
    "path_2 = '/kaggle/input/face-mask-lite-dataset/with_mask'\n",
    "\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "files_1 = sorted_alphanumeric([f for f in os.listdir(path_1) if os.path.isfile(os.path.join(path_1, f))])[:NoofIMGs]\n",
    "files_2 = sorted_alphanumeric([f for f in os.listdir(path_2) if os.path.isfile(os.path.join(path_2, f))])[:NoofIMGs]\n",
    "files_3 = sorted_alphanumeric([f for f in os.listdir(path_1) if os.path.isfile(os.path.join(path_1, f))])[NoofIMGs:]\n",
    "files_4 = sorted_alphanumeric([f for f in os.listdir(path_2) if os.path.isfile(os.path.join(path_2, f))])[NoofIMGs:]\n",
    "without_mask_paths = [os.path.join(path_1, fname) for fname in files_1]\n",
    "with_mask_paths = [os.path.join(path_2, fname) for fname in files_2]\n",
    "without_mask_val_paths=[os.path.join(path_1, fname) for fname in files_3]\n",
    "with_mask_val_paths = [os.path.join(path_2, fname) for fname in files_4]\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')  \n",
    "    img = img.resize((SIZE, SIZE))  \n",
    "    img = np.array(img) / 127.5 - 1.0  \n",
    "    return tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def create_dataset(without_mask_paths, with_mask_paths):\n",
    "    def generator():\n",
    "        for without_mask_path, with_mask_path in zip(without_mask_paths, with_mask_paths):\n",
    "            without_mask_img = load_and_preprocess_image(without_mask_path)\n",
    "            with_mask_img = load_and_preprocess_image(with_mask_path)\n",
    "            yield without_mask_img, with_mask_img\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(SIZE, SIZE, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(SIZE, SIZE, 3), dtype=tf.float32),\n",
    "        )\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_dataset(without_mask_paths, with_mask_paths)\n",
    "val_dataset=create_dataset(without_mask_val_paths, with_mask_val_paths)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for without_mask_img, with_mask_img in train_dataset.take(1):\n",
    "    print(\"Without mask image shape:\", without_mask_img.shape)\n",
    "    print(\"With mask image shape:\", with_mask_img.shape)\n",
    "for without_mask_img, with_mask_img in val_dataset.take(1):\n",
    "    print(\"Without mask image shape:\", without_mask_img.shape)\n",
    "    print(\"With mask image shape:\", with_mask_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:34:18.273793Z",
     "iopub.status.busy": "2024-12-14T02:34:18.273540Z",
     "iopub.status.idle": "2024-12-14T02:34:18.753409Z",
     "shell.execute_reply": "2024-12-14T02:34:18.752530Z",
     "shell.execute_reply.started": "2024-12-14T02:34:18.273769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow((without_mask_img[i].numpy() + 1) / 2)  # Chuyển ảnh về [0, 1]\n",
    "    plt.title(\"UnMasked\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    plt.imshow((with_mask_img[i].numpy() + 1) / 2)  # Chuyển ảnh về [0, 1]\n",
    "    plt.title(\"Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:34:18.754741Z",
     "iopub.status.busy": "2024-12-14T02:34:18.754472Z",
     "iopub.status.idle": "2024-12-14T02:34:22.846919Z",
     "shell.execute_reply": "2024-12-14T02:34:22.846046Z",
     "shell.execute_reply.started": "2024-12-14T02:34:18.754716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Double Convolutional Block\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Conv2D(out_channels, kernel_size=3, padding='same', activation=None),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(out_channels, kernel_size=3, padding='same', activation=None),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU()\n",
    "    ])\n",
    "\n",
    "def Generator(input_shape=(128, 128, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv_1 = double_conv(3, 64)(inputs)\n",
    "    pool_1 = layers.MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
    "\n",
    "    conv_2 = double_conv(64, 128)(pool_1)\n",
    "    pool_2 = layers.MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
    "\n",
    "    conv_3 = double_conv(128, 256)(pool_2)\n",
    "    pool_3 = layers.MaxPooling2D(pool_size=(2, 2))(conv_3)\n",
    "\n",
    "    conv_4 = double_conv(256, 512)(pool_3)\n",
    "    pool_4 = layers.MaxPooling2D(pool_size=(2, 2))(conv_4)\n",
    "\n",
    "    conv_5 = double_conv(512, 1024)(pool_4)\n",
    "\n",
    "    # Decoder\n",
    "    upconv_1 = layers.Conv2DTranspose(512, kernel_size=2, strides=2, padding='same')(conv_5)\n",
    "    concat_1 = layers.Concatenate()([upconv_1, conv_4])\n",
    "    conv_6 = double_conv(1024, 512)(concat_1)\n",
    "\n",
    "    upconv_2 = layers.Conv2DTranspose(256, kernel_size=2, strides=2, padding='same')(conv_6)\n",
    "    concat_2 = layers.Concatenate()([upconv_2, conv_3])\n",
    "    conv_7 = double_conv(512, 256)(concat_2)\n",
    "\n",
    "    upconv_3 = layers.Conv2DTranspose(128, kernel_size=2, strides=2, padding='same')(conv_7)\n",
    "    concat_3 = layers.Concatenate()([upconv_3, conv_2])\n",
    "    conv_8 = double_conv(256, 128)(concat_3)\n",
    "\n",
    "    upconv_4 = layers.Conv2DTranspose(64, kernel_size=2, strides=2, padding='same')(conv_8)\n",
    "    concat_4 = layers.Concatenate()([upconv_4, conv_1])\n",
    "    conv_9 = double_conv(128, 64)(concat_4)\n",
    "\n",
    "    output = layers.Conv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')(conv_9)\n",
    "\n",
    "    return tf.keras.Model(inputs, output)\n",
    "\n",
    "generator = tf.keras.models.load_model('/kaggle/input/asdfasdf/tensorflow2/default/1/generator_final.h5')\n",
    "\n",
    "# Test generator \n",
    "dummy_input = tf.random.normal([1, 128, 128, 3])  # Batch of 1, 128x128 RGB image\n",
    "output = generator(dummy_input)\n",
    "print(\"Generator output shape:\", output.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:34:22.848496Z",
     "iopub.status.busy": "2024-12-14T02:34:22.848097Z",
     "iopub.status.idle": "2024-12-14T02:36:07.532353Z",
     "shell.execute_reply": "2024-12-14T02:36:07.531458Z",
     "shell.execute_reply.started": "2024-12-14T02:34:22.848455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for without_mask_imgs, with_mask_imgs in train_dataset.take(1):\n",
    "    # Test generator trên ảnh không có khẩu trang\n",
    "    generated_imgs = generator(with_mask_imgs)\n",
    "\n",
    "    print(f\"Input batch shape: {without_mask_imgs.shape}\")\n",
    "    print(f\"Generated batch shape: {generated_imgs.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:36:07.533913Z",
     "iopub.status.busy": "2024-12-14T02:36:07.533651Z",
     "iopub.status.idle": "2024-12-14T02:36:07.863713Z",
     "shell.execute_reply": "2024-12-14T02:36:07.862809Z",
     "shell.execute_reply.started": "2024-12-14T02:36:07.533889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def denormalize(img):\n",
    "    return (img + 1) / 2 \n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Hiển thị ảnh đầu vào không có khẩu trang\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(denormalize(without_mask_imgs[0].numpy()))  # Ảnh đầu tiên trong batch\n",
    "plt.title(\"Without Mask (Input)\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Hiển thị ảnh được tạo ra bởi generator\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denormalize(generated_imgs[0].numpy()))  # Ảnh đầu tiên trong batch\n",
    "plt.title(\"Generated Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:36:07.864943Z",
     "iopub.status.busy": "2024-12-14T02:36:07.864704Z",
     "iopub.status.idle": "2024-12-14T02:36:08.095148Z",
     "shell.execute_reply": "2024-12-14T02:36:08.094353Z",
     "shell.execute_reply.started": "2024-12-14T02:36:07.864920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def Discriminator(input_shape=(128, 128, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(inputs)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)  # Output là xác suất thật/giả\n",
    "\n",
    "    return tf.keras.Model(inputs, x)\n",
    "\n",
    "# Instantiate the discriminator\n",
    "discriminator = tf.keras.models.load_model('/kaggle/input/asdfasdf/tensorflow2/default/1/discriminator.h5')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:36:08.103099Z",
     "iopub.status.busy": "2024-12-14T02:36:08.102832Z",
     "iopub.status.idle": "2024-12-14T02:36:08.117975Z",
     "shell.execute_reply": "2024-12-14T02:36:08.117293Z",
     "shell.execute_reply.started": "2024-12-14T02:36:08.103075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:36:08.119233Z",
     "iopub.status.busy": "2024-12-14T02:36:08.118961Z",
     "iopub.status.idle": "2024-12-14T02:36:08.123790Z",
     "shell.execute_reply": "2024-12-14T02:36:08.122964Z",
     "shell.execute_reply.started": "2024-12-14T02:36:08.119200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output),fake_output)\n",
    "def discriminator_loss(fake_output, real_output):\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
    "    return fake_loss + real_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:36:08.124869Z",
     "iopub.status.busy": "2024-12-14T02:36:08.124662Z",
     "iopub.status.idle": "2024-12-14T02:36:08.139481Z",
     "shell.execute_reply": "2024-12-14T02:36:08.138627Z",
     "shell.execute_reply.started": "2024-12-14T02:36:08.124849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(without_mask_imgs, with_mask_imgs):\n",
    "    \n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "        \n",
    "        generated_imgs = generator(with_mask_imgs, training=True)\n",
    "\n",
    "        \n",
    "        real_output = discriminator(without_mask_imgs, training=True)\n",
    "        fake_output = discriminator(generated_imgs, training=True)\n",
    "\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(fake_output, real_output)\n",
    "\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:36:08.141290Z",
     "iopub.status.busy": "2024-12-14T02:36:08.140514Z",
     "iopub.status.idle": "2024-12-14T02:36:08.149571Z",
     "shell.execute_reply": "2024-12-14T02:36:08.148763Z",
     "shell.execute_reply.started": "2024-12-14T02:36:08.141252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(without_mask_imgs, with_mask_imgs):\n",
    "    \n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "        \n",
    "        generated_imgs = generator(with_mask_imgs, training=False)\n",
    "\n",
    "        \n",
    "        real_output = discriminator(without_mask_imgs, training=False)\n",
    "        fake_output = discriminator(generated_imgs, training=False)\n",
    "\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(fake_output, real_output)\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:36:08.229751Z",
     "iopub.status.busy": "2024-12-14T02:36:08.229395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    print(\"\\nEpoch : {}\".format(epoch + 1))\n",
    "\n",
    "\n",
    "    total_gen_loss_train = 0.0\n",
    "    total_dis_loss_train = 0.0\n",
    "    total_gen_loss_val = 0.0\n",
    "    total_dis_loss_val = 0.0\n",
    "    num_batches_train= 0\n",
    "    num_batches_val=0\n",
    "\n",
    "    for without_mask_imgs, with_mask_imgs in train_dataset:\n",
    "        gen_loss, disc_loss = train_step(without_mask_imgs, with_mask_imgs)\n",
    "        total_gen_loss_train += gen_loss\n",
    "        total_dis_loss_train += disc_loss\n",
    "        num_batches_train += 1\n",
    "    \n",
    "    \n",
    "    avg_gen_loss_train = total_gen_loss_train / num_batches_train\n",
    "    avg_dis_loss_train = total_dis_loss_train / num_batches_train\n",
    "\n",
    "\n",
    "    \n",
    "    for without_mask_imgs, with_mask_imgs in val_dataset:\n",
    "        gen_loss, disc_loss = val_step(without_mask_imgs, with_mask_imgs)\n",
    "        total_gen_loss_val += gen_loss\n",
    "        total_dis_loss_val += disc_loss\n",
    "        num_batches_val += 1\n",
    "    avg_gen_loss_val = total_gen_loss_val / num_batches_val\n",
    "    avg_dis_loss_val = total_dis_loss_val / num_batches_val\n",
    "\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        for without_mask_imgs, _ in train_dataset.take(1):\n",
    "            generated_imgs = generator(with_mask_imgs)\n",
    "            plt.imshow((generated_imgs[0].numpy() + 1) / 2)  # Hiển thị ảnh đầu tiên trong batch\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    print(\" Time:{}\".format(np.round(time.time() - start, 2)))\n",
    "    print(\"Avg Generator Loss Train: {:.4f} Avg Discriminator Loss Train: {:.4f}  Avg Generator Loss Val: {:.4f} Avg Discriminator Loss Val: {:.4f}\".format(avg_gen_loss_train, avg_dis_loss_train,avg_gen_loss_val,avg_dis_loss_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T05:05:35.879512Z",
     "iopub.status.busy": "2024-12-14T05:05:35.879165Z",
     "iopub.status.idle": "2024-12-14T05:05:35.896735Z",
     "shell.execute_reply": "2024-12-14T05:05:35.895743Z",
     "shell.execute_reply.started": "2024-12-14T05:05:35.879482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generator.save('/kaggle/working/generator_new_final.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 770718,
     "sourceId": 1328233,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 190695,
     "modelInstanceId": 168352,
     "sourceId": 197404,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
